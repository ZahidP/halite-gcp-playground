{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_dir = os.environ.get('HALITE_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not code_dir:\n",
    "    code_dir = '/'.join(os.getcwd().split('/')[:-1] + ['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(code_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_environments import make\n",
    "from kaggle_environments.envs.halite.helpers import Board, ShipAction, ShipyardAction, Observation\n",
    "from halite_env import HaliteEnv\n",
    "from ship_state_wrapper import ShipStateWrapper\n",
    "from shipyard_state_wrapper import ShipYardStateWrapper\n",
    "from agent import Agent\n",
    "from game_runner_v2 import GameRunner\n",
    "from halite_agent import HaliteAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from play import train_agent, play_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/tiger37/reinforcement-learning-meets-halite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward_results = train_agent(10, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4,5,6]\n",
    "a[len(a)//3:len(a)//3*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = play_games(3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = results['all_scores']\n",
    "ship_agent = results['ship_agent']\n",
    "shipyard_agent = results['shipyard_agent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for episode in rewards[-5:]:\n",
    "    i += 1\n",
    "    episode = np.array(episode)\n",
    "    for j in range(episode.shape[1]):\n",
    "        plt.subplot(3, 2, i)\n",
    "        sns.lineplot(x=range(0, episode.shape[0]), y=episode[:, j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing Already Trained Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = make('halite', {}, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = environment.train([None, \"random\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Instantiating Wrappers Because They Hold State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_state_wrapper = ShipStateWrapper(\n",
    "    radius=4,\n",
    "    max_frames=2,\n",
    "    map_size=1\n",
    ")\n",
    "shipyard_state_wrapper = ShipYardStateWrapper(\n",
    "    radius=4,\n",
    "    max_frames=1,\n",
    "    map_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Instatiating Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halite_env = HaliteEnv(\n",
    "    opponents=3,\n",
    "    ship_state_wrapper=ship_state_wrapper,\n",
    "    shipyard_state_wrapper=shipyard_state_wrapper,\n",
    "    radius=4,\n",
    "    environment=None,\n",
    "    trainer=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Agent\n",
    "\n",
    "Note: In a submission file we should use an already trained agent and load from the Kaggle/Outputs directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halite_agent = HaliteAgent(\n",
    "    configuration=environment.configuration,\n",
    "    halite_env=halite_env,\n",
    "    ship_agent=ship_agent,\n",
    "    shipyard_agent=shipyard_agent,\n",
    "    training=False,\n",
    "    verbose=False,\n",
    "    ship_frame_stack_len=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_environments.envs.halite.helpers import Board, Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent Runner Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def halite_run_agent(observation, configuration):\n",
    "    \n",
    "    halite_agent.env.ship_state_wrapper.set_map_size(configuration['size'])\n",
    "    halite_agent.env.shipyard_state_wrapper.set_map_size(configuration['size'])\n",
    "    \n",
    "    raw_observation = observation\n",
    "    step_observation = Observation(observation)\n",
    "    \n",
    "    raw_observation, shipyard_simulated_step_memory = halite_agent.get_moves_for_all_shipyards(\n",
    "        raw_observation=raw_observation,\n",
    "        step_observation=step_observation,\n",
    "        episode_number=0,\n",
    "        step_number=0\n",
    "    )\n",
    "\n",
    "    raw_observation, ship_simulated_step_memory = halite_agent.get_moves_for_all_ships(\n",
    "        raw_observation=raw_observation,\n",
    "        step_observation=step_observation,\n",
    "        episode_number=0,\n",
    "        step_number=0\n",
    "    )\n",
    "\n",
    "    actions_for_step = halite_agent.actions_for_step\n",
    "    return actions_for_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_result = environment.run([halite_run_agent, \"random\", \"random\", \"random\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(run_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_result[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = environment.train([None, \"random\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = trainer.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "halite_run_agent(state, environment.configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation, game_reward, terminal = step_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile submission.py\n",
    "\n",
    "def halite_run_agent(observation, configuration):\n",
    "    \n",
    "    halite_agent.env.ship_state_wrapper.set_map_size(configuration['size'])\n",
    "    halite_agent.env.shipyard_state_wrapper.set_map_size(configuration['size'])\n",
    "    \n",
    "    raw_observation = observation\n",
    "    step_observation = Observation(observation)\n",
    "    \n",
    "    raw_observation, shipyard_simulated_step_memory = halite_agent.get_moves_for_all_shipyards(\n",
    "        raw_observation=raw_observation,\n",
    "        step_observation=step_observation,\n",
    "        episode_number=0,\n",
    "        step_number=0\n",
    "    )\n",
    "\n",
    "    raw_observation, ship_simulated_step_memory = halite_agent.get_moves_for_all_ships(\n",
    "        raw_observation=raw_observation,\n",
    "        step_observation=step_observation,\n",
    "        episode_number=0,\n",
    "        step_number=0\n",
    "    )\n",
    "\n",
    "    actions_for_step = halite_agent.actions_for_step\n",
    "    return actions_for_step\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
